{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU 체크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %load device_test.py\n",
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \",\"  # use CPU only\n",
    "# del os.environ[\"CUDA_VISIBLE_DEVICES\"]\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"tf.test.is_built_with_cuda():\", tf.test.is_built_with_cuda())\n",
    "print(\"tf.test.is_gpu_available():\", tf.test.is_gpu_available())\n",
    "\n",
    "sess = tf.Session()\n",
    "if (sess.list_devices): # for tensorflow 1.3+\n",
    "      for d in sess.list_devices():\n",
    "          print(d.name)\n",
    "sess.close()\n",
    "\n",
    "# Undocumented feature\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hello program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load hello.py\n",
    "import tensorflow as tf\n",
    "\n",
    "sess = tf.Session()\n",
    "hello = tf.constant('Hello, TensorFlow!') # node (operation)\n",
    "print(sess.run(hello)) # data flow graph의 실행\n",
    "\n",
    "sess.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 플로우 그래프\n",
    "- 하나의 데이터 플로 그래프 표현\n",
    "- 연산을 나타내는 노드(node)와 노드간에 교환되는 데이터인 엣지(edge)로 구성된다.\n",
    "- 노드간에 교환되는 데이터는 스칼라, 벡터, 행렬 등 다차원 배열을 의미하는 텐서(tensor)이다.\n",
    "![Alt text](graph_test.png)\n",
    "\n",
    "- Const:0 => Const에 0 출력\n",
    "- Const_1:0 => Const_1에 1 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load graph_test.py\n",
    "import tensorflow as tf\n",
    "\n",
    "a = tf.constant(1.0)   #1.0 이라는 텐서 변수에 저장\n",
    "b = tf.constant(2.0)   #2.0 이라는 텐서 변수에 저장\n",
    "c = a + b\n",
    "\n",
    "print(type(a), \",\", a)\n",
    "print(type(b), \",\", b)\n",
    "print(type(c), \",\", c)  #결과적으로 텐서 3개가 만들어짐."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"get_operations():\")  \n",
    "\n",
    "#operation 객체가 node 객체인데 모두 출력.\n",
    "for op in tf.get_default_graph().get_operations():\n",
    "    print(\"op.name: \", op.name, \", op.type: \", op.type, \", op.inputs: \", [x for x in op.inputs],\n",
    "              \", op.outputs: \", [x for x in op.outputs], sep=\"\")\n",
    "g = tf.get_default_graph()\n",
    "print(a.graph is g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Const:\", g.get_operation_by_name(\"Const\"))\n",
    "print(\"Const.output[0]:\", g.get_operation_by_name(\"Const\").outputs[0])\n",
    "print(\"Const:0\", g.get_tensor_by_name(\"Const:0\"))\n",
    "print(\"a:\", a, type(a))\n",
    "print(\"a.name: \", a.name, \", a.op.name: \", a.op.name, \", a.value_index: \", a.value_index,\n",
    "          \", a.shape: \", a.shape, \", a.dtype: \", a.dtype, sep=\"\")\n",
    "\n",
    "print(\"Const_1:\", g.get_operation_by_name(\"Const_1\"))\n",
    "print(\"Const_1.outputs[0]:\", g.get_operation_by_name(\"Const_1\").outputs[0])\n",
    "print(\"Const_1:0\", g.get_tensor_by_name(\"Const_1:0\"))\n",
    "print(\"b:\", b, type(b))\n",
    "print(\"b.name: \", b.name, \", b.op.name: \", b.op.name, \", b.value_index: \", b.value_index,\n",
    "          \", b.shape: \", b.shape, \", b.dtype: \", b.dtype, sep=\"\")\n",
    "\n",
    "print(\"add:\", g.get_operation_by_name(\"add\"))\n",
    "print(\"add.outputs[0]:\", g.get_operation_by_name(\"add\").outputs[0])\n",
    "print(\"add.inputs[0]:\", g.get_operation_by_name(\"add\").inputs[0])\n",
    "print(\"add.inputs[1]:\", g.get_operation_by_name(\"add\").inputs[1])\n",
    "print(\"c:\", c, type(c))\n",
    "print(\"c.name: \", c.name, \", c.op.name: \", c.op.name, \", c.value_index: \", c.value_index,\n",
    "          \", c.shape: \", c.shape, \", c.dtype: \", c.dtype, sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "v = sess.run(g.get_tensor_by_name(\"Const:0\"))   #run 에서 나올때는 numpy 타입으로 나옴\n",
    "print(\"%s: %r\\n\" % (type(v), v))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 세션 관리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load session_test.py\n",
    "import tensorflow as tf\n",
    "\n",
    "# 텐서플로 기본 그래프 생성\n",
    "a = tf.constant(1)\n",
    "b = tf.constant(2)\n",
    "c = a + b\n",
    "addOp = tf.get_default_graph().get_operation_by_name(\"add\")\n",
    "\n",
    "# 세션 생성 및 닫기\n",
    "sess = tf.Session()\n",
    "v = sess.run(c)                   #c를 실행하기 위해 내부적으로 a와 b도 실행됨.\n",
    "print(\"%s: %r\\n\" % (type(v), v))\n",
    "v = sess.run(addOp)               #addOp도 따로 실행 가능.\n",
    "print(\"%s: %r\\n\" % (type(v), v))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 세션 생성 및 자동 닫기 (with 안에 있는 두 문장이 실행되고 자동으로 세션 닫음)\n",
    "with tf.Session() as sess:\n",
    "    v = sess.run(c)\n",
    "    print(\"%s: %r\\n\" % (type(v), v))\n",
    "\n",
    "# 기본 세션 (as_default())\n",
    "sess = tf.Session()\n",
    "with sess.as_default():                #sess 객체를 생성 후 default세션 지정. (with 안에서만)\n",
    "    v = addOp.run()\n",
    "    print(\"%s: %r\\n\" % (type(v), v))\n",
    "    v = c.eval()\n",
    "    print(\"%s: %r\\n\" % (type(v), v))\n",
    "\n",
    "sess.close()\n",
    "\n",
    "# 기본 세션 (tf.InteractiveSession)\n",
    "sess = tf.InteractiveSession()         #만드는 즉시 default 세션이 됨\n",
    "v = addOp.run()\n",
    "print(\"%s: %r\\n\" % (type(v), v))\n",
    "v = c.eval()\n",
    "print(\"%s: %r\\n\" % (type(v), v))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load session_inout_test.py\n",
    "# tensorflow에서는 numpy나 list 지원.\n",
    "import tensorflow as tf\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "a = tf.constant(1)\n",
    "b = tf.constant(2)\n",
    "c = a + b\n",
    "x = tf.constant([10, 20])         #list를 텐서로 만듦\n",
    "y = tf.constant([1.0, 2.0])\n",
    "\n",
    "v = sess.run(a)\n",
    "print(\"%s: %r\\n\" % (type(v), v))\n",
    "\n",
    "v = sess.run(c)\n",
    "print(\"%s: %r\\n\" % (type(v), v))\n",
    "\n",
    "v = sess.run(x)                   #numpy 형태로 출력됨.\n",
    "print(\"%s: %r\\n\" % (type(v), v))\n",
    "\n",
    "v = sess.run([x, y])              #numpy 형태가 묶여서 리스트 형태로 출력됨. (run에서 지정해준대로 출력된다)\n",
    "print(\"%s: %r\\n\" % (type(v), v))\n",
    "\n",
    "import collections\n",
    "MyData = collections.namedtuple('MyData', ['x', 'y'])\n",
    "v = sess.run({'k1': MyData(x, y), 'k2': [y, x]})\n",
    "print(\"%s: %r\\n\" % (type(v), v))\n",
    "\n",
    "v = sess.run(c, feed_dict={a: 3, b: 4})    #feed_dict는 텐서를 변경할 때 사용. 외부 데이터를 input할 때.\n",
    "print(v)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 상수\n",
    "상수 텐서와 그 상수 텐서의 값을 채우는 텐서 연산을 생성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load constant_test.py\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 값 상수 텐서\n",
    "\n",
    "c1 = tf.constant(1.0)\n",
    "print(type(c1), \",\", c1, \",\", c1.shape, \",\", c1.dtype, \",\", sess.run(c1))\n",
    "c2 = tf.constant([1.0, 2.0, 3.0])\n",
    "print(c2.shape, \",\", c2.dtype, \",\", sess.run(c2))\n",
    "c3 = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "print(c3.shape, \",\", c3.dtype, \",\", sess.run(c3))\n",
    "c4 = tf.constant(np.array([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]]))\n",
    "print(c4.shape, \",\", c4.dtype, \",\", sess.run(c4))\n",
    "c5 = tf.constant(1.0, shape=(2,3))\n",
    "print(c5.shape, \",\", c5.dtype, \",\", sess.run(c5))\n",
    "c6 = tf.constant([1.0, 2.0], shape=(2,3))\n",
    "print(c6.shape, \",\", c6.dtype, \",\", sess.run(c6))\n",
    "c7 = tf.constant([1, 2, 3])\n",
    "print(c7.dtype, \",\", sess.run(c7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 특정값 상수 텐서\n",
    "\n",
    "print(sess.run(tf.zeros([3])))           #0으로 초기화된 텐서\n",
    "print(sess.run(tf.ones([3])))            #1로 초기화된 텐서\n",
    "print(sess.run(tf.fill([3], 2.0)))\n",
    "print(sess.run(tf.zeros_like((c2))))\n",
    "print(sess.run(tf.ones_like((c2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 시퀀스\n",
    "\n",
    "c8 = tf.range(1, 5)\n",
    "print(type(c8), \",\", c8, \",\", sess.run(c8))\n",
    "c9 = tf.range(5)\n",
    "print(type(c9), \",\", c9, \",\", sess.run(c9))\n",
    "print(sess.run(tf.lin_space(1.0, 3.0, 3)))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 변수\n",
    "여러 세션간에 공유되어 영속적으로 존재하는 변수 (tf.Variable 클래스)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load variable_test.py\n",
    "import tensorflow as tf\n",
    "\n",
    "#get_variable 이 권장되는 방법. 참조해서 있으면 사용하고 없으면 생성하기 때문.\n",
    "v1 = tf.get_variable(\"v1\", (2,))                 #첫번째 인자가 변수명, 두번째 인자가 크기. #(2,)에서 ',' 역할은 tuple을 만들기 위해\n",
    "v2 = tf.get_variable(\"v2\", (2,), dtype=tf.int32)\n",
    "v3 = tf.get_variable(\"v3\", dtype=tf.int32, initializer=tf.constant([3, 4]))        #옵션에서 값을 대입해서 초기화까지 시켜준다.\n",
    "\n",
    "assign = v1.assign(tf.constant([3.0, 4.0]))      #변수에 값을 대입할 때는 assign 함수를 사용해서 대입한다.\n",
    "print(type(v1), v1)\n",
    "\n",
    "init = tf.global_variables_initializer()         #초기화해주는 함수\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)                               #초기화 된 변수를 run해줘야 함.\n",
    "    print(sess.run([v1, v2, v3, assign]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# placeholder\n",
    "노드에 전달되는 매개 변수 역할 (텐서의 일종)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load placeholder_test.py\n",
    "import tensorflow as tf\n",
    "\n",
    "a = tf.placeholder(tf.int16)    #일단 자료형 지정\n",
    "b = tf.placeholder(tf.int16)\n",
    "\n",
    "print(type(a), a)\n",
    "\n",
    "add = tf.add(a, b) # same with 'a + b'\n",
    "mul = tf.multiply(a, b) # same with 'a * b'\n",
    "print(mul)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(\"Addition with variables: %d\" % sess.run(add, feed_dict={a:2, b:3}))\n",
    "    print(\"Multiplication with variables: %d\" % sess.run(mul, feed_dict={a:2, b:3}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load matmul_test.py\n",
    "import tensorflow as tf\n",
    "\n",
    "a = tf.constant([[3., 3.]])  # 1 x 2 matrix\n",
    "b = tf.constant([[2.], [2.]]) # 2 x 1 matrix\n",
    "\n",
    "product = tf.matmul(a, b)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(product))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU와 CPU 속도 비교\n",
    "\n",
    "- GPU의 경우 24000 * 24000 이 5초 걸림\n",
    "- CPU의 경우 24000 * 24000 이 120초 걸림"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load matmul_speed_test.py\n",
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \",\"  # use CPU only\n",
    "# del os.environ[\"CUDA_VISIBLE_DEVICES\"]\n",
    "\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "for size in [1000, 2000, 4000, 8000, 16000, 24000]:  # 12 MB, 48 MB, 192 MB, 768 MB, 3 GB, 6.75 GB\n",
    "    a = tf.random_uniform((size, size), 0.0, 1.0)\n",
    "    b = tf.random_uniform((size, size), 0.0, 1.0)\n",
    "    c = tf.matmul(a, b)\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        start = time.time()\n",
    "        sess.run(c)\n",
    "        end = time.time()\n",
    "\n",
    "    print(\"%s: %f 초\" % (c.shape, end - start))\n",
    "    a = b = c = None    # 쓰레기 수집\n",
    "    tf.reset_default_graph()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 최적화 문제 - 분석적 해법 (최적 해)\n",
    "\n",
    "- 손실 함수    \n",
    "    - x^4 - 3 x^3 + 2\n",
    "- 풀이\n",
    "    - f'(x) = 4 x^3 - 9 x^2 = 0\n",
    "    - f(0) = 2\n",
    "    - f(2.25) = 2.25^4 - 3*2.25^3 + 2 = -6.54296875"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  절차적 해법 (근사 해)\n",
    "- 실제로는 위의 방법처럼 인수분해를 통해 찾기 어렵기 때문에 근사 해를 찾는다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load gradient_descent_test.py\n",
    "## 학습 알고리듬 설정\n",
    "x = 6 # The algorithm starts at x=6     #초기값\n",
    "delta = 0.01 # step size\n",
    "n = 50 # number of learning iterations\n",
    "\n",
    "## 손실 함수\n",
    "def f(x):\n",
    "    return x ** 4 - 3 * x ** 3 + 2\n",
    "\n",
    "## 수작업 미분 함수\n",
    "def f_derivative(x):\n",
    "    return 4 * x**3 - 9 * x**2\n",
    "\n",
    "## 경사하강 학습\n",
    "print(\"%3d: f(%f) = %f\" % (0, x, f(x)))\n",
    "\n",
    "for count in range(n):\n",
    "    x -= delta * f_derivative(x)\n",
    "    print(\"%3d: f(%f) = %f\" % ((count+1), x, f(x)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 절차적 해법 (텐서플로)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load gradient_descent_tf_test.py\n",
    "import tensorflow as tf\n",
    "\n",
    "precision = 0.00001\n",
    "\n",
    "## 최적화 함수 정의\n",
    "\n",
    "x = tf.get_variable(\"x\", initializer=6.0)\n",
    "y = x**4 - 3 * x**3 + 2                      # x가 텐서이기 때문에 전부 다 텐서 연산이 된다.\n",
    "\n",
    "## 경사 하강 알고리듬 설정\n",
    "\n",
    "a = tf.get_variable(\"a\", initializer=0.01) # learning rate, alpha\n",
    "optimizer = tf.train.GradientDescentOptimizer(a)\n",
    "train = optimizer.minimize(y)\n",
    "\n",
    "# 변수 초기화\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "## 훈련\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "count = 0\n",
    "x_old = 0\n",
    "x_new = sess.run(x)\n",
    "print(\"%3d: f(%f) = %f, precision: %f\" % (count, x_new, sess.run(y), x_new - x_old))\n",
    "\n",
    "# 한번 돌 때마다 한번 학습\n",
    "while abs(x_new - x_old) > precision:\n",
    "    count += 1\n",
    "    x_old = x_new\n",
    "    sess.run(train)\n",
    "    x_new = sess.run(x)\n",
    "    print(\"%3d: f(%f) = %f, precision: %f\" % (count, x_new, sess.run(y), x_new - x_old))\n",
    "\n",
    "print(\"Local minimum occurs at\", x_new)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 경사하강 학습법 - 단순 선형회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load simple_linear_regression_gd_tf_test.py\n",
    "import tensorflow as tf\n",
    "\n",
    "## 데이터 수집\n",
    "\n",
    "x_data = [1, 2, 3]\n",
    "y_data = [1, 2, 3]\n",
    "\n",
    "## 예측 모델 정의\n",
    "\n",
    "W = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n",
    "b = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n",
    "y = W * x_data + b            #예측값\n",
    "\n",
    "## 비용 함수, 최적화 함수 정의\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(y - y_data))     # reduce_mean 함수로 벡터값을 스칼라값으로 바꿔줌. \n",
    "a = tf.Variable(0.1) # learning rate, alpha      # 학습률을 변경할수도 있기때문에 변수지정\n",
    "optimizer = tf.train.GradientDescentOptimizer(a)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# 변수 초기화\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "## 훈련\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for step in range(2001):\n",
    "    sess.run(train)\n",
    "    if step % 20 == 0:\n",
    "        print(step, sess.run(cost), sess.run(W), sess.run(b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %load simple_linear_regression_gd_tf_placeholder_test.py\n",
    "import tensorflow as tf\n",
    "\n",
    "## 데이터 수집\n",
    "\n",
    "x_data = [1, 2, 3]\n",
    "y_data = [1, 2, 3]\n",
    "\n",
    "## 예측 모델 정의\n",
    "\n",
    "X = tf.placeholder(\"float\")\n",
    "y = tf.placeholder(\"float\")\n",
    "W = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n",
    "b = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n",
    "pred = W * X + b\n",
    "\n",
    "## 비용 함수, 최적화 함수 정의\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(pred - y))\n",
    "a = tf.Variable(0.1) # learning rate, alpha\n",
    "optimizer = tf.train.GradientDescentOptimizer(a)\n",
    "train = optimizer.minimize(cost)\n",
    "# 변수 초기화\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "## 훈련\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for step in range(2001):\n",
    "    sess.run(train, feed_dict = {X: x_data, y: y_data}) \n",
    "    if step % 20 == 0:\n",
    "        cost_, W_, b_ = sess.run([cost, W, b], feed_dict = {X: x_data, y: y_data}) \n",
    "        print(step, cost_, W_, b_)\n",
    "\n",
    "print(sess.run(pred, feed_dict = {X: [2]}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 실제 예시 (insurance.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load insurance_simple_linear_regression_gd_tf_test.py\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "## 데이터 수집\n",
    "\n",
    "insurance = pd.read_csv(\"insurance.csv\")\n",
    "print(insurance[0:5])\n",
    "\n",
    "age = insurance[\"age\"].values\n",
    "expenses = insurance[\"expenses\"].values\n",
    "\n",
    "print(\"\\n [age, expenses] : \",[age,expenses])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 예측 모델 정의\n",
    "X = tf.placeholder(\"float\")\n",
    "Y = tf.placeholder(\"float\")\n",
    "\n",
    "tf_coef = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n",
    "tf_intercept = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n",
    "tf_expenses_pred = tf_coef * X + tf_intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 비용 함수, 최적화 함수 정의\n",
    "tf_cost = tf.reduce_mean(tf.square(tf_expenses_pred - Y))\n",
    "a = tf.Variable(0.0001)\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(a)\n",
    "train = optimizer.minimize(tf_cost)\n",
    "\n",
    "#변수 초기화\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 훈련\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "for step in range(300000):\n",
    "  sess.run(train, feed_dict={X: age, Y: expenses})\n",
    "  if step % 10000 == 0:\n",
    "    cost, coef, intercept = sess.run([tf_cost, tf_coef, tf_intercept], feed_dict={X: age, Y: expenses})\n",
    "    print(step, cost, math.sqrt(cost), coef, intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 예측\n",
    "coef = sess.run(tf_coef)\n",
    "intercept = sess.run(tf_interceopt)\n",
    "print(coef * np.array[20, 40, 60])\n",
    "......\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 텐서보드 (TensorBoard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "알고리듬이 어떻게 돌아가고 있는지 알려주기 위해 많은 정보를 모니터링하고 디스플레이해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!c:\\anaconda3\\scripts\\tensorboard --logdir /tmp/summary_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load summary_test.py\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "## 데이터 수집\n",
    "\n",
    "x_data = [1, 2, 3]\n",
    "y_data = [1, 2, 3]\n",
    "\n",
    "## 예측 모델 정의\n",
    "\n",
    "W = tf.get_variable(\"W\", initializer=tf.random_uniform([1], -1.0, 1.0))\n",
    "b = tf.get_variable(\"b\", initializer=tf.random_uniform([1], -1.0, 1.0))\n",
    "y = W * x_data + b\n",
    "\n",
    "## 비용 함수, 최적화 함수 정의\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(y - y_data))\n",
    "alpha = tf.get_variable(\"alpha\", initializer=0.01) # learning rate, alpha\n",
    "optimizer = tf.train.GradientDescentOptimizer(alpha)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "## 초기화, summary and graph log\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "tf.summary.scalar(\"cost\", cost)\n",
    "tf.summary.scalar(\"W\", W[0])\n",
    "tf.summary.scalar(\"b\", b[0])\n",
    "\n",
    "summary_op = tf.summary.merge_all()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "sess = tf.Session()\n",
    "summary_writer = tf.summary.FileWriter(\"summary_logs/\", sess.graph)\n",
    "sess.run(init)\n",
    "\n",
    "## 훈련\n",
    "\n",
    "for step in range(500):\n",
    "    sess.run(train)\n",
    "    if step % 20 == 0:\n",
    "        print(step, sess.run(cost), sess.run(W), sess.run(b))\n",
    "    summary_str = sess.run(summary_op)\n",
    "    summary_writer.add_summary(summary_str, step)\n",
    "    saver.save(sess, \"summary_logs/model-checkpoint\", global_stbep=step)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://localhost:6006 방문"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: c:Anaconda3tensorboard: not found\r\n"
     ]
    }
   ],
   "source": [
    "!c:\\Anaconda3\\tensorboard --logdir /tmp/mnist_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# %load mnist_softmax_gd_tf_summary_test.py\n",
    "# Copyright (c) 2016-2017, Deogtae Kim & DTWARE Inc. All rights reserved.\n",
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \",\"\n",
    "# del os.environ[\"CUDA_VISIBLE_DEVICES\"]\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(107)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-7d9a8ca6f7a8>:4: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/user/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/user/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /home/user/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/user/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/user/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "<class 'tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet'>\n",
      "['__add__', '__class__', '__contains__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getnewargs__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__rmul__', '__setattr__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '_asdict', '_fields', '_make', '_replace', '_source', 'count', 'index', 'test', 'train', 'validation']\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "(55000, 784)\n",
      "(784,)\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.3803922  0.37647063 0.3019608\n",
      " 0.46274513 0.2392157  0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.3529412\n",
      " 0.5411765  0.9215687  0.9215687  0.9215687  0.9215687  0.9215687\n",
      " 0.9215687  0.9843138  0.9843138  0.9725491  0.9960785  0.9607844\n",
      " 0.9215687  0.74509805 0.08235294 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.54901963 0.9843138  0.9960785  0.9960785\n",
      " 0.9960785  0.9960785  0.9960785  0.9960785  0.9960785  0.9960785\n",
      " 0.9960785  0.9960785  0.9960785  0.9960785  0.9960785  0.9960785\n",
      " 0.7411765  0.09019608 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.8862746  0.9960785  0.81568635 0.7803922  0.7803922  0.7803922\n",
      " 0.7803922  0.54509807 0.2392157  0.2392157  0.2392157  0.2392157\n",
      " 0.2392157  0.5019608  0.8705883  0.9960785  0.9960785  0.7411765\n",
      " 0.08235294 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.14901961 0.32156864\n",
      " 0.0509804  0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.13333334 0.8352942  0.9960785  0.9960785  0.45098042 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.32941177\n",
      " 0.9960785  0.9960785  0.9176471  0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.32941177 0.9960785  0.9960785\n",
      " 0.9176471  0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.4156863  0.6156863  0.9960785  0.9960785  0.95294124 0.20000002\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.09803922\n",
      " 0.45882356 0.8941177  0.8941177  0.8941177  0.9921569  0.9960785\n",
      " 0.9960785  0.9960785  0.9960785  0.94117653 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.26666668 0.4666667  0.86274517 0.9960785  0.9960785\n",
      " 0.9960785  0.9960785  0.9960785  0.9960785  0.9960785  0.9960785\n",
      " 0.9960785  0.5568628  0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.14509805 0.73333335 0.9921569\n",
      " 0.9960785  0.9960785  0.9960785  0.8745099  0.8078432  0.8078432\n",
      " 0.29411766 0.26666668 0.8431373  0.9960785  0.9960785  0.45882356\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.4431373  0.8588236  0.9960785  0.9490197  0.89019614 0.45098042\n",
      " 0.34901962 0.12156864 0.         0.         0.         0.\n",
      " 0.7843138  0.9960785  0.9450981  0.16078432 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.6627451  0.9960785\n",
      " 0.6901961  0.24313727 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.18823531 0.9058824  0.9960785\n",
      " 0.9176471  0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.07058824 0.48627454 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.32941177 0.9960785  0.9960785  0.6509804  0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.54509807\n",
      " 0.9960785  0.9333334  0.22352943 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.8235295  0.9803922  0.9960785  0.65882355\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.9490197  0.9960785  0.93725497 0.22352943 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.34901962 0.9843138  0.9450981\n",
      " 0.3372549  0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.01960784 0.8078432  0.96470594 0.6156863  0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.01568628 0.45882356\n",
      " 0.27058825 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n",
      "(55000, 10)\n",
      "(10,)\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "55000 (55000, 784) (55000, 10)\n",
      "5000 (5000, 784) (5000, 10)\n",
      "10000 (10000, 784) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "## 데이터 수집\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "\n",
    "## 데이터 시각화, 전처리\n",
    "\n",
    "print(type(mnist.train))\n",
    "print(dir(mnist))\n",
    "print(type(mnist.train.images), type(mnist.train.labels))\n",
    "print(mnist.train.images.shape)\n",
    "print(mnist.train.images[0].shape)\n",
    "print(mnist.train.images[0])\n",
    "print(mnist.train.labels.shape)\n",
    "print(mnist.train.labels[0].shape)\n",
    "print(mnist.train.labels[0])\n",
    "print(mnist.train.num_examples, mnist.train.images.shape, mnist.train.labels.shape)\n",
    "print(mnist.validation.num_examples, mnist.validation.images.shape, mnist.validation.labels.shape)\n",
    "print(mnist.test.num_examples, mnist.test.images.shape, mnist.test.labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAEICAYAAABhxi57AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff9b443e8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline          \n",
    "# 시각화하는 패키지. 웹브라우져에서 보여줄 수 있게끔 inline으로 선언\n",
    "fig, axes = plt.subplots(5, 5)\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        axes[i,j].axis('off')\n",
    "        axes[i,j].imshow(mnist.train.images[i*5+j].reshape(28,28))\n",
    "        axes[i,j].set_title(\"%d\" % np.argmax(mnist.train.labels[i*5+j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 예측 모델 정의: 소프트맥스 회귀 모델\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 784])                 # 행의 개수 변경 없으므로 None\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "W = tf.get_variable(\"W\", initializer=tf.zeros([784, 10]))\n",
    "b = tf.get_variable(\"b\", initializer=tf.zeros([10]))\n",
    "# 각 데이터에 대한 각 분류별 점수\n",
    "score = tf.matmul(X, W) + b         # 행렬의 곱이기 때문에 matmul(W, X)가 아닌 matmul(X, W). [5500, 784] * [784, 10]이 되어야 하므로\n",
    "# 각 데이터에 대한 각 분류별 확률\n",
    "pred = tf.nn.softmax(score)\n",
    "\n",
    "## 손실 함수, 정확도, 최적화 함수 정의\n",
    "\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(pred), reduction_indices=[1]))\n",
    "correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(Y, 1))                    # 숫자로 바꿔주는 코드.\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "#train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cost)\n",
    "train_step = tf.train.AdamOptimizer(0.001).minimize(cost)\n",
    "\n",
    "# 로그 초기화\n",
    "\n",
    "tf.summary.histogram(\"W histogram\", W)\n",
    "tf.summary.histogram(\"b histogram\", b)\n",
    "tf.summary.scalar(\"cost\", cost)\n",
    "tf.summary.scalar(\"accuracy\", accuracy)\n",
    "\n",
    "summary_op = tf.summary.merge_all()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "sess = tf.Session()\n",
    "summary_writer = tf.summary.FileWriter(\"mnist_logs/\", sess.graph)\n",
    "\n",
    "## 훈련\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "import time\n",
    "start = time.time()\n",
    "for epoch in range(50):\n",
    "    avg_cost = 0\n",
    "    batch_count = int(mnist.train.num_examples / 100)\n",
    "    for _ in range(batch_count):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "        c, _  = sess.run([cost, train_step], feed_dict={X: batch_xs, Y: batch_ys})\n",
    "        avg_cost += c / batch_count\n",
    "#    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost), \n",
    "#          ', accuacy = ', '{:.9f}'.format(sess.run(accuracy, feed_dict={X: mnist.test.images, Y: mnist.test.labels})))\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost), \n",
    "          ', validation accuacy = ', '{:.9f}'.format(sess.run(accuracy, feed_dict={X: mnist.validation.images, Y: mnist.validation.labels})))\n",
    "    summary_str = sess.run(summary_op, feed_dict={X: mnist.validation.images, Y: mnist.validation.labels})\n",
    "    summary_writer.add_summary(summary_str, epoch)\n",
    "    saver.save(sess, \"mnist_logs/model-checkpoint\", global_step=epoch)\n",
    "    \n",
    "print('accuacy = ', '{:.9f}'.format(sess.run(accuracy, feed_dict={X: mnist.test.images, Y: mnist.test.labels})))\n",
    "print(\"훈련 시간:\", time.time() - start)  \n",
    "\n",
    "## 모델 평가\n",
    "\n",
    "print(sess.run(accuracy, feed_dict={X: mnist.test.images, Y: mnist.test.labels}))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://localhost:6006 방문"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
