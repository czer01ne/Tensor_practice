{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU 체크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %load device_test.py\n",
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \",\"  # use CPU only\n",
    "# del os.environ[\"CUDA_VISIBLE_DEVICES\"]\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"tf.test.is_built_with_cuda():\", tf.test.is_built_with_cuda())\n",
    "print(\"tf.test.is_gpu_available():\", tf.test.is_gpu_available())\n",
    "\n",
    "sess = tf.Session()\n",
    "if (sess.list_devices): # for tensorflow 1.3+\n",
    "      for d in sess.list_devices():\n",
    "          print(d.name)\n",
    "sess.close()\n",
    "\n",
    "# Undocumented feature\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hello program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load hello.py\n",
    "import tensorflow as tf\n",
    "\n",
    "sess = tf.Session()\n",
    "hello = tf.constant('Hello, TensorFlow!') # node (operation)\n",
    "print(sess.run(hello)) # data flow graph의 실행\n",
    "\n",
    "sess.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 플로우 그래프\n",
    "- 하나의 데이터 플로 그래프 표현\n",
    "- 연산을 나타내는 노드(node)와 노드간에 교환되는 데이터인 엣지(edge)로 구성된다.\n",
    "- 노드간에 교환되는 데이터는 스칼라, 벡터, 행렬 등 다차원 배열을 의미하는 텐서(tensor)이다.\n",
    "![Alt text](graph_test.png)\n",
    "\n",
    "- Const:0 => Const에 0 출력\n",
    "- Const_1:0 => Const_1에 1 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load graph_test.py\n",
    "import tensorflow as tf\n",
    "\n",
    "a = tf.constant(1.0)   #1.0 이라는 텐서 변수에 저장\n",
    "b = tf.constant(2.0)   #2.0 이라는 텐서 변수에 저장\n",
    "c = a + b\n",
    "\n",
    "print(type(a), \",\", a)\n",
    "print(type(b), \",\", b)\n",
    "print(type(c), \",\", c)  #결과적으로 텐서 3개가 만들어짐."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"get_operations():\")  \n",
    "\n",
    "#operation 객체가 node 객체인데 모두 출력.\n",
    "for op in tf.get_default_graph().get_operations():\n",
    "    print(\"op.name: \", op.name, \", op.type: \", op.type, \", op.inputs: \", [x for x in op.inputs],\n",
    "              \", op.outputs: \", [x for x in op.outputs], sep=\"\")\n",
    "g = tf.get_default_graph()\n",
    "print(a.graph is g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Const:\", g.get_operation_by_name(\"Const\"))\n",
    "print(\"Const.output[0]:\", g.get_operation_by_name(\"Const\").outputs[0])\n",
    "print(\"Const:0\", g.get_tensor_by_name(\"Const:0\"))\n",
    "print(\"a:\", a, type(a))\n",
    "print(\"a.name: \", a.name, \", a.op.name: \", a.op.name, \", a.value_index: \", a.value_index,\n",
    "          \", a.shape: \", a.shape, \", a.dtype: \", a.dtype, sep=\"\")\n",
    "\n",
    "print(\"Const_1:\", g.get_operation_by_name(\"Const_1\"))\n",
    "print(\"Const_1.outputs[0]:\", g.get_operation_by_name(\"Const_1\").outputs[0])\n",
    "print(\"Const_1:0\", g.get_tensor_by_name(\"Const_1:0\"))\n",
    "print(\"b:\", b, type(b))\n",
    "print(\"b.name: \", b.name, \", b.op.name: \", b.op.name, \", b.value_index: \", b.value_index,\n",
    "          \", b.shape: \", b.shape, \", b.dtype: \", b.dtype, sep=\"\")\n",
    "\n",
    "print(\"add:\", g.get_operation_by_name(\"add\"))\n",
    "print(\"add.outputs[0]:\", g.get_operation_by_name(\"add\").outputs[0])\n",
    "print(\"add.inputs[0]:\", g.get_operation_by_name(\"add\").inputs[0])\n",
    "print(\"add.inputs[1]:\", g.get_operation_by_name(\"add\").inputs[1])\n",
    "print(\"c:\", c, type(c))\n",
    "print(\"c.name: \", c.name, \", c.op.name: \", c.op.name, \", c.value_index: \", c.value_index,\n",
    "          \", c.shape: \", c.shape, \", c.dtype: \", c.dtype, sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "v = sess.run(g.get_tensor_by_name(\"Const:0\"))   #run 에서 나올때는 numpy 타입으로 나옴\n",
    "print(\"%s: %r\\n\" % (type(v), v))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 세션 관리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load session_test.py\n",
    "import tensorflow as tf\n",
    "\n",
    "# 텐서플로 기본 그래프 생성\n",
    "a = tf.constant(1)\n",
    "b = tf.constant(2)\n",
    "c = a + b\n",
    "addOp = tf.get_default_graph().get_operation_by_name(\"add\")\n",
    "\n",
    "# 세션 생성 및 닫기\n",
    "sess = tf.Session()\n",
    "v = sess.run(c)                   #c를 실행하기 위해 내부적으로 a와 b도 실행됨.\n",
    "print(\"%s: %r\\n\" % (type(v), v))\n",
    "v = sess.run(addOp)               #addOp도 따로 실행 가능.\n",
    "print(\"%s: %r\\n\" % (type(v), v))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 세션 생성 및 자동 닫기 (with 안에 있는 두 문장이 실행되고 자동으로 세션 닫음)\n",
    "with tf.Session() as sess:\n",
    "    v = sess.run(c)\n",
    "    print(\"%s: %r\\n\" % (type(v), v))\n",
    "\n",
    "# 기본 세션 (as_default())\n",
    "sess = tf.Session()\n",
    "with sess.as_default():                #sess 객체를 생성 후 default세션 지정. (with 안에서만)\n",
    "    v = addOp.run()\n",
    "    print(\"%s: %r\\n\" % (type(v), v))\n",
    "    v = c.eval()\n",
    "    print(\"%s: %r\\n\" % (type(v), v))\n",
    "\n",
    "sess.close()\n",
    "\n",
    "# 기본 세션 (tf.InteractiveSession)\n",
    "sess = tf.InteractiveSession()         #만드는 즉시 default 세션이 됨\n",
    "v = addOp.run()\n",
    "print(\"%s: %r\\n\" % (type(v), v))\n",
    "v = c.eval()\n",
    "print(\"%s: %r\\n\" % (type(v), v))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load session_inout_test.py\n",
    "# tensorflow에서는 numpy나 list 지원.\n",
    "import tensorflow as tf\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "a = tf.constant(1)\n",
    "b = tf.constant(2)\n",
    "c = a + b\n",
    "x = tf.constant([10, 20])         #list를 텐서로 만듦\n",
    "y = tf.constant([1.0, 2.0])\n",
    "\n",
    "v = sess.run(a)\n",
    "print(\"%s: %r\\n\" % (type(v), v))\n",
    "\n",
    "v = sess.run(c)\n",
    "print(\"%s: %r\\n\" % (type(v), v))\n",
    "\n",
    "v = sess.run(x)                   #numpy 형태로 출력됨.\n",
    "print(\"%s: %r\\n\" % (type(v), v))\n",
    "\n",
    "v = sess.run([x, y])              #numpy 형태가 묶여서 리스트 형태로 출력됨. (run에서 지정해준대로 출력된다)\n",
    "print(\"%s: %r\\n\" % (type(v), v))\n",
    "\n",
    "import collections\n",
    "MyData = collections.namedtuple('MyData', ['x', 'y'])\n",
    "v = sess.run({'k1': MyData(x, y), 'k2': [y, x]})\n",
    "print(\"%s: %r\\n\" % (type(v), v))\n",
    "\n",
    "v = sess.run(c, feed_dict={a: 3, b: 4})    #feed_dict는 텐서를 변경할 때 사용. 외부 데이터를 input할 때.\n",
    "print(v)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 상수\n",
    "상수 텐서와 그 상수 텐서의 값을 채우는 텐서 연산을 생성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load constant_test.py\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 값 상수 텐서\n",
    "\n",
    "c1 = tf.constant(1.0)\n",
    "print(type(c1), \",\", c1, \",\", c1.shape, \",\", c1.dtype, \",\", sess.run(c1))\n",
    "c2 = tf.constant([1.0, 2.0, 3.0])\n",
    "print(c2.shape, \",\", c2.dtype, \",\", sess.run(c2))\n",
    "c3 = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "print(c3.shape, \",\", c3.dtype, \",\", sess.run(c3))\n",
    "c4 = tf.constant(np.array([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]]))\n",
    "print(c4.shape, \",\", c4.dtype, \",\", sess.run(c4))\n",
    "c5 = tf.constant(1.0, shape=(2,3))\n",
    "print(c5.shape, \",\", c5.dtype, \",\", sess.run(c5))\n",
    "c6 = tf.constant([1.0, 2.0], shape=(2,3))\n",
    "print(c6.shape, \",\", c6.dtype, \",\", sess.run(c6))\n",
    "c7 = tf.constant([1, 2, 3])\n",
    "print(c7.dtype, \",\", sess.run(c7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특정값 상수 텐서\n",
    "\n",
    "print(sess.run(tf.zeros([3])))           #0으로 초기화된 텐서\n",
    "print(sess.run(tf.ones([3])))            #1로 초기화된 텐서\n",
    "print(sess.run(tf.fill([3], 2.0)))\n",
    "print(sess.run(tf.zeros_like((c2))))\n",
    "print(sess.run(tf.ones_like((c2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시퀀스\n",
    "\n",
    "c8 = tf.range(1, 5)\n",
    "print(type(c8), \",\", c8, \",\", sess.run(c8))\n",
    "c9 = tf.range(5)\n",
    "print(type(c9), \",\", c9, \",\", sess.run(c9))\n",
    "print(sess.run(tf.lin_space(1.0, 3.0, 3)))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 변수\n",
    "여러 세션간에 공유되어 영속적으로 존재하는 변수 (tf.Variable 클래스)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.ops.variables.Variable'> <tf.Variable 'v1:0' shape=(2,) dtype=float32_ref>\n",
      "[array([3., 4.], dtype=float32), array([0, 0], dtype=int32), array([3, 4], dtype=int32), array([3., 4.], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "# %load variable_test.py\n",
    "import tensorflow as tf\n",
    "\n",
    "#get_variable 이 권장되는 방법. 참조해서 있으면 사용하고 없으면 생성하기 때문.\n",
    "v1 = tf.get_variable(\"v1\", (2,))                 #첫번째 인자가 변수명, 두번째 인자가 크기. #(2,)에서 ',' 역할은 tuple을 만들기 위해\n",
    "v2 = tf.get_variable(\"v2\", (2,), dtype=tf.int32)\n",
    "v3 = tf.get_variable(\"v3\", dtype=tf.int32, initializer=tf.constant([3, 4]))        #옵션에서 값을 대입해서 초기화까지 시켜준다.\n",
    "\n",
    "assign = v1.assign(tf.constant([3.0, 4.0]))      #변수에 값을 대입할 때는 assign 함수를 사용해서 대입한다.\n",
    "print(type(v1), v1)\n",
    "\n",
    "init = tf.global_variables_initializer()         #초기화해주는 함수\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)                               #초기화 된 변수를 run해줘야 함.\n",
    "    print(sess.run([v1, v2, v3, assign]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# placeholder\n",
    "노드에 전달되는 매개 변수 역할 (텐서의 일종)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.Tensor'> Tensor(\"Placeholder:0\", dtype=int16)\n",
      "Tensor(\"Mul:0\", dtype=int16)\n",
      "Addition with variables: 5\n",
      "Multiplication with variables: 6\n"
     ]
    }
   ],
   "source": [
    "# %load placeholder_test.py\n",
    "import tensorflow as tf\n",
    "\n",
    "a = tf.placeholder(tf.int16)    #일단 자료형 지정\n",
    "b = tf.placeholder(tf.int16)\n",
    "\n",
    "print(type(a), a)\n",
    "\n",
    "add = tf.add(a, b) # same with 'a + b'\n",
    "mul = tf.multiply(a, b) # same with 'a * b'\n",
    "print(mul)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(\"Addition with variables: %d\" % sess.run(add, feed_dict={a:2, b:3}))\n",
    "    print(\"Multiplication with variables: %d\" % sess.run(mul, feed_dict={a:2, b:3}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12.]]\n"
     ]
    }
   ],
   "source": [
    "# %load matmul_test.py\n",
    "import tensorflow as tf\n",
    "\n",
    "a = tf.constant([[3., 3.]])  # 1 x 2 matrix\n",
    "b = tf.constant([[2.], [2.]]) # 2 x 1 matrix\n",
    "\n",
    "product = tf.matmul(a, b)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(product))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU와 CPU 속도 비교\n",
    "\n",
    "- GPU의 경우 24000 * 24000 이 5초 걸림\n",
    "- CPU의 경우 24000 * 24000 이 120초 걸림"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1000): 0.021663 초\n",
      "(2000, 2000): 0.079224 초\n",
      "(4000, 4000): 0.566750 초\n",
      "(8000, 8000): 4.334068 초\n",
      "(16000, 16000): 34.308139 초\n",
      "(24000, 24000): 119.312975 초\n"
     ]
    }
   ],
   "source": [
    "# %load matmul_speed_test.py\n",
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \",\"  # use CPU only\n",
    "# del os.environ[\"CUDA_VISIBLE_DEVICES\"]\n",
    "\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "for size in [1000, 2000, 4000, 8000, 16000, 24000]:  # 12 MB, 48 MB, 192 MB, 768 MB, 3 GB, 6.75 GB\n",
    "    a = tf.random_uniform((size, size), 0.0, 1.0)\n",
    "    b = tf.random_uniform((size, size), 0.0, 1.0)\n",
    "    c = tf.matmul(a, b)\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        start = time.time()\n",
    "        sess.run(c)\n",
    "        end = time.time()\n",
    "\n",
    "    print(\"%s: %f 초\" % (c.shape, end - start))\n",
    "    a = b = c = None    # 쓰레기 수집\n",
    "    tf.reset_default_graph()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 최적화 문제 - 분석적 해법 (최적 해)\n",
    "\n",
    "- 손실 함수    \n",
    "    - x^4 - 3 x^3 + 2\n",
    "- 풀이\n",
    "    - f'(x) = 4 x^3 - 9 x^2 = 0\n",
    "    - f(0) = 2\n",
    "    - f(2.25) = 2.25^4 - 3*2.25^3 + 2 = -6.54296875"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  절차적 해법 (근사 해)\n",
    "- 실제로는 위의 방법처럼 인수분해를 통해 찾기 어렵기 때문에 근사 해를 찾는다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0: f(6.000000) = 650.000000\n",
      "  1: f(0.600000) = 1.481600\n",
      "  2: f(0.623760) = 1.423309\n",
      "  3: f(0.649069) = 1.357145\n",
      "  4: f(0.676048) = 1.281943\n",
      "  5: f(0.704822) = 1.196373\n",
      "  6: f(0.735526) = 1.098924\n",
      "  7: f(0.768299) = 0.987891\n",
      "  8: f(0.803284) = 0.861373\n",
      "  9: f(0.840625) = 0.717271\n",
      " 10: f(0.880462) = 0.553317\n",
      " 11: f(0.922930) = 0.367110\n",
      " 12: f(0.968146) = 0.156197\n",
      " 13: f(1.016205) = -0.081809\n",
      " 14: f(1.067169) = -0.349059\n",
      " 15: f(1.121052) = -0.647233\n",
      " 16: f(1.177805) = -0.977246\n",
      " 17: f(1.237300) = -1.338898\n",
      " 18: f(1.299314) = -1.730494\n",
      " 19: f(1.363512) = -2.148489\n",
      " 20: f(1.429437) = -2.587232\n",
      " 21: f(1.496503) = -3.038898\n",
      " 22: f(1.564002) = -3.493712\n",
      " 23: f(1.631123) = -3.940522\n",
      " 24: f(1.696986) = -4.367716\n",
      " 25: f(1.760688) = -4.764375\n",
      " 26: f(1.821363) = -5.121467\n",
      " 27: f(1.878240) = -5.432815\n",
      " 28: f(1.930700) = -5.695626\n",
      " 29: f(1.978309) = -5.910464\n",
      " 30: f(2.020842) = -6.080715\n",
      " 31: f(2.058275) = -6.211724\n",
      " 32: f(2.090765) = -6.309823\n",
      " 33: f(2.118607) = -6.381483\n",
      " 34: f(2.142198) = -6.432684\n",
      " 35: f(2.161986) = -6.468566\n",
      " 36: f(2.178442) = -6.493295\n",
      " 37: f(2.192025) = -6.510096\n",
      " 38: f(2.203168) = -6.521374\n",
      " 39: f(2.212261) = -6.528869\n",
      " 40: f(2.219649) = -6.533808\n",
      " 41: f(2.225630) = -6.537042\n",
      " 42: f(2.230459) = -6.539147\n",
      " 43: f(2.234347) = -6.540511\n",
      " 44: f(2.237473) = -6.541392\n",
      " 45: f(2.239982) = -6.541959\n",
      " 46: f(2.241992) = -6.542323\n",
      " 47: f(2.243602) = -6.542556\n",
      " 48: f(2.244891) = -6.542705\n",
      " 49: f(2.245920) = -6.542801\n",
      " 50: f(2.246744) = -6.542862\n"
     ]
    }
   ],
   "source": [
    "# %load gradient_descent_test.py\n",
    "## 학습 알고리듬 설정\n",
    "x = 6 # The algorithm starts at x=6     #초기값\n",
    "delta = 0.01 # step size\n",
    "n = 50 # number of learning iterations\n",
    "\n",
    "## 손실 함수\n",
    "def f(x):\n",
    "    return x ** 4 - 3 * x ** 3 + 2\n",
    "\n",
    "## 수작업 미분 함수\n",
    "def f_derivative(x):\n",
    "    return 4 * x**3 - 9 * x**2\n",
    "\n",
    "## 경사하강 학습\n",
    "print(\"%3d: f(%f) = %f\" % (0, x, f(x)))\n",
    "\n",
    "for count in range(n):\n",
    "    x -= delta * f_derivative(x)\n",
    "    print(\"%3d: f(%f) = %f\" % ((count+1), x, f(x)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 절차적 해법 (텐서플로)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0: f(6.000000) = 650.000000, precision: 6.000000\n",
      "  1: f(0.600000) = 1.481600, precision: -5.400000\n",
      "  2: f(0.623760) = 1.423310, precision: 0.023760\n",
      "  3: f(0.649069) = 1.357145, precision: 0.025309\n",
      "  4: f(0.676048) = 1.281943, precision: 0.026978\n",
      "  5: f(0.704822) = 1.196373, precision: 0.028774\n",
      "  6: f(0.735526) = 1.098924, precision: 0.030704\n",
      "  7: f(0.768299) = 0.987891, precision: 0.032773\n",
      "  8: f(0.803284) = 0.861373, precision: 0.034985\n",
      "  9: f(0.840625) = 0.717272, precision: 0.037341\n",
      " 10: f(0.880462) = 0.553317, precision: 0.039837\n",
      " 11: f(0.922930) = 0.367110, precision: 0.042467\n",
      " 12: f(0.968145) = 0.156197, precision: 0.045216\n",
      " 13: f(1.016205) = -0.081808, precision: 0.048060\n",
      " 14: f(1.067169) = -0.349058, precision: 0.050964\n",
      " 15: f(1.121052) = -0.647232, precision: 0.053883\n",
      " 16: f(1.177804) = -0.977245, precision: 0.056753\n",
      " 17: f(1.237299) = -1.338897, precision: 0.059495\n",
      " 18: f(1.299314) = -1.730492, precision: 0.062014\n",
      " 19: f(1.363512) = -2.148487, precision: 0.064198\n",
      " 20: f(1.429437) = -2.587230, precision: 0.065925\n",
      " 21: f(1.496503) = -3.038896, precision: 0.067066\n",
      " 22: f(1.564002) = -3.493711, precision: 0.067499\n",
      " 23: f(1.631123) = -3.940521, precision: 0.067121\n",
      " 24: f(1.696985) = -4.367714, precision: 0.065862\n",
      " 25: f(1.760687) = -4.764374, precision: 0.063702\n",
      " 26: f(1.821362) = -5.121465, precision: 0.060675\n",
      " 27: f(1.878240) = -5.432814, precision: 0.056878\n",
      " 28: f(1.930700) = -5.695625, precision: 0.052460\n",
      " 29: f(1.978309) = -5.910462, precision: 0.047609\n",
      " 30: f(2.020842) = -6.080713, precision: 0.042533\n",
      " 31: f(2.058275) = -6.211723, precision: 0.037434\n",
      " 32: f(2.090765) = -6.309822, precision: 0.032490\n",
      " 33: f(2.118608) = -6.381483, precision: 0.027843\n",
      " 34: f(2.142198) = -6.432686, precision: 0.023590\n",
      " 35: f(2.161986) = -6.468565, precision: 0.019788\n",
      " 36: f(2.178442) = -6.493294, precision: 0.016456\n",
      " 37: f(2.192025) = -6.510096, precision: 0.013583\n",
      " 38: f(2.203168) = -6.521374, precision: 0.011143\n",
      " 39: f(2.212260) = -6.528870, precision: 0.009093\n",
      " 40: f(2.219649) = -6.533813, precision: 0.007388\n",
      " 41: f(2.225630) = -6.537041, precision: 0.005981\n",
      " 42: f(2.230459) = -6.539148, precision: 0.004829\n",
      " 43: f(2.234347) = -6.540514, precision: 0.003889\n",
      " 44: f(2.237473) = -6.541391, precision: 0.003126\n",
      " 45: f(2.239982) = -6.541956, precision: 0.002509\n",
      " 46: f(2.241992) = -6.542324, precision: 0.002011\n",
      " 47: f(2.243602) = -6.542557, precision: 0.001610\n",
      " 48: f(2.244890) = -6.542704, precision: 0.001288\n",
      " 49: f(2.245920) = -6.542801, precision: 0.001030\n",
      " 50: f(2.246743) = -6.542862, precision: 0.000823\n",
      " 51: f(2.247401) = -6.542902, precision: 0.000658\n",
      " 52: f(2.247926) = -6.542927, precision: 0.000525\n",
      " 53: f(2.248345) = -6.542946, precision: 0.000419\n",
      " 54: f(2.248680) = -6.542955, precision: 0.000335\n",
      " 55: f(2.248947) = -6.542957, precision: 0.000267\n",
      " 56: f(2.249160) = -6.542963, precision: 0.000213\n",
      " 57: f(2.249330) = -6.542965, precision: 0.000170\n",
      " 58: f(2.249465) = -6.542969, precision: 0.000136\n",
      " 59: f(2.249574) = -6.542965, precision: 0.000108\n",
      " 60: f(2.249660) = -6.542969, precision: 0.000086\n",
      " 61: f(2.249729) = -6.542969, precision: 0.000069\n",
      " 62: f(2.249784) = -6.542967, precision: 0.000055\n",
      " 63: f(2.249828) = -6.542967, precision: 0.000044\n",
      " 64: f(2.249862) = -6.542973, precision: 0.000035\n",
      " 65: f(2.249890) = -6.542967, precision: 0.000028\n",
      " 66: f(2.249913) = -6.542969, precision: 0.000022\n",
      " 67: f(2.249930) = -6.542969, precision: 0.000018\n",
      " 68: f(2.249944) = -6.542969, precision: 0.000014\n",
      " 69: f(2.249955) = -6.542971, precision: 0.000011\n",
      " 70: f(2.249964) = -6.542969, precision: 0.000009\n",
      "Local minimum occurs at 2.2499645\n"
     ]
    }
   ],
   "source": [
    "# %load gradient_descent_tf_test.py\n",
    "import tensorflow as tf\n",
    "\n",
    "precision = 0.00001\n",
    "\n",
    "## 최적화 함수 정의\n",
    "\n",
    "x = tf.get_variable(\"x\", initializer=6.0)\n",
    "y = x**4 - 3 * x**3 + 2                      # x가 텐서이기 때문에 전부 다 텐서 연산이 된다.\n",
    "\n",
    "## 경사 하강 알고리듬 설정\n",
    "\n",
    "a = tf.get_variable(\"a\", initializer=0.01) # learning rate, alpha\n",
    "optimizer = tf.train.GradientDescentOptimizer(a)\n",
    "train = optimizer.minimize(y)\n",
    "\n",
    "# 변수 초기화\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "## 훈련\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "count = 0\n",
    "x_old = 0\n",
    "x_new = sess.run(x)\n",
    "print(\"%3d: f(%f) = %f, precision: %f\" % (count, x_new, sess.run(y), x_new - x_old))\n",
    "\n",
    "# 한번 돌 때마다 한번 학습\n",
    "while abs(x_new - x_old) > precision:\n",
    "    count += 1\n",
    "    x_old = x_new\n",
    "    sess.run(train)\n",
    "    x_new = sess.run(x)\n",
    "    print(\"%3d: f(%f) = %f, precision: %f\" % (count, x_new, sess.run(y), x_new - x_old))\n",
    "\n",
    "print(\"Local minimum occurs at\", x_new)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 경사하강 학습법 - 단순 선형회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.24355374 [1.0495875] [0.39267302]\n",
      "20 0.0052333125 [0.91597974] [0.19099787]\n",
      "40 0.0019772847 [0.9483547] [0.11740182]\n",
      "60 0.00074707175 [0.96825486] [0.07216416]\n",
      "80 0.00028226516 [0.98048705] [0.04435762]\n",
      "100 0.00010664671 [0.9880059] [0.02726554]\n",
      "120 4.0294795e-05 [0.9926275] [0.01675951]\n",
      "140 1.52242255e-05 [0.99546826] [0.0103017]\n",
      "160 5.752321e-06 [0.9972145] [0.00633221]\n",
      "180 2.1733406e-06 [0.99828774] [0.0038923]\n",
      "200 8.21269e-07 [0.99894756] [0.00239254]\n",
      "220 3.1029634e-07 [0.9993531] [0.00147068]\n",
      "240 1.17242315e-07 [0.9996023] [0.00090396]\n",
      "260 4.4295334e-08 [0.99975556] [0.00055569]\n",
      "280 1.6737625e-08 [0.99984974] [0.00034156]\n",
      "300 6.3209504e-09 [0.9999076] [0.00020992]\n",
      "320 2.3932973e-09 [0.9999432] [0.00012905]\n",
      "340 9.0276825e-10 [0.9999651] [7.932001e-05]\n",
      "360 3.4030734e-10 [0.99997854] [4.8778587e-05]\n",
      "380 1.2875508e-10 [0.9999868] [3.0022995e-05]\n",
      "400 4.8411646e-11 [0.9999919] [1.8404065e-05]\n",
      "420 1.863043e-11 [0.999995] [1.1291241e-05]\n",
      "440 6.9964776e-12 [0.99999696] [6.9599714e-06]\n",
      "460 2.444267e-12 [0.99999815] [4.273789e-06]\n",
      "480 8.7159907e-13 [0.99999887] [2.620754e-06]\n",
      "500 3.2684966e-13 [0.9999993] [1.6035017e-06]\n",
      "520 1.563194e-13 [0.9999996] [9.995085e-07]\n",
      "540 6.158037e-14 [0.99999964] [7.1340645e-07]\n",
      "560 6.158037e-14 [0.99999976] [5.8624994e-07]\n",
      "580 2.3684757e-14 [0.9999998] [3.3193675e-07]\n",
      "600 4.7369517e-15 [0.99999994] [1.5709638e-07]\n",
      "620 0.0 [1.] [5.378164e-08]\n",
      "640 0.0 [1.] [5.378164e-08]\n",
      "660 0.0 [1.] [5.378164e-08]\n",
      "680 0.0 [1.] [5.378164e-08]\n",
      "700 0.0 [1.] [5.378164e-08]\n",
      "720 0.0 [1.] [5.378164e-08]\n",
      "740 0.0 [1.] [5.378164e-08]\n",
      "760 0.0 [1.] [5.378164e-08]\n",
      "780 0.0 [1.] [5.378164e-08]\n",
      "800 0.0 [1.] [5.378164e-08]\n",
      "820 0.0 [1.] [5.378164e-08]\n",
      "840 0.0 [1.] [5.378164e-08]\n",
      "860 0.0 [1.] [5.378164e-08]\n",
      "880 0.0 [1.] [5.378164e-08]\n",
      "900 0.0 [1.] [5.378164e-08]\n",
      "920 0.0 [1.] [5.378164e-08]\n",
      "940 0.0 [1.] [5.378164e-08]\n",
      "960 0.0 [1.] [5.378164e-08]\n",
      "980 0.0 [1.] [5.378164e-08]\n",
      "1000 0.0 [1.] [5.378164e-08]\n",
      "1020 0.0 [1.] [5.378164e-08]\n",
      "1040 0.0 [1.] [5.378164e-08]\n",
      "1060 0.0 [1.] [5.378164e-08]\n",
      "1080 0.0 [1.] [5.378164e-08]\n",
      "1100 0.0 [1.] [5.378164e-08]\n",
      "1120 0.0 [1.] [5.378164e-08]\n",
      "1140 0.0 [1.] [5.378164e-08]\n",
      "1160 0.0 [1.] [5.378164e-08]\n",
      "1180 0.0 [1.] [5.378164e-08]\n",
      "1200 0.0 [1.] [5.378164e-08]\n",
      "1220 0.0 [1.] [5.378164e-08]\n",
      "1240 0.0 [1.] [5.378164e-08]\n",
      "1260 0.0 [1.] [5.378164e-08]\n",
      "1280 0.0 [1.] [5.378164e-08]\n",
      "1300 0.0 [1.] [5.378164e-08]\n",
      "1320 0.0 [1.] [5.378164e-08]\n",
      "1340 0.0 [1.] [5.378164e-08]\n",
      "1360 0.0 [1.] [5.378164e-08]\n",
      "1380 0.0 [1.] [5.378164e-08]\n",
      "1400 0.0 [1.] [5.378164e-08]\n",
      "1420 0.0 [1.] [5.378164e-08]\n",
      "1440 0.0 [1.] [5.378164e-08]\n",
      "1460 0.0 [1.] [5.378164e-08]\n",
      "1480 0.0 [1.] [5.378164e-08]\n",
      "1500 0.0 [1.] [5.378164e-08]\n",
      "1520 0.0 [1.] [5.378164e-08]\n",
      "1540 0.0 [1.] [5.378164e-08]\n",
      "1560 0.0 [1.] [5.378164e-08]\n",
      "1580 0.0 [1.] [5.378164e-08]\n",
      "1600 0.0 [1.] [5.378164e-08]\n",
      "1620 0.0 [1.] [5.378164e-08]\n",
      "1640 0.0 [1.] [5.378164e-08]\n",
      "1660 0.0 [1.] [5.378164e-08]\n",
      "1680 0.0 [1.] [5.378164e-08]\n",
      "1700 0.0 [1.] [5.378164e-08]\n",
      "1720 0.0 [1.] [5.378164e-08]\n",
      "1740 0.0 [1.] [5.378164e-08]\n",
      "1760 0.0 [1.] [5.378164e-08]\n",
      "1780 0.0 [1.] [5.378164e-08]\n",
      "1800 0.0 [1.] [5.378164e-08]\n",
      "1820 0.0 [1.] [5.378164e-08]\n",
      "1840 0.0 [1.] [5.378164e-08]\n",
      "1860 0.0 [1.] [5.378164e-08]\n",
      "1880 0.0 [1.] [5.378164e-08]\n",
      "1900 0.0 [1.] [5.378164e-08]\n",
      "1920 0.0 [1.] [5.378164e-08]\n",
      "1940 0.0 [1.] [5.378164e-08]\n",
      "1960 0.0 [1.] [5.378164e-08]\n",
      "1980 0.0 [1.] [5.378164e-08]\n",
      "2000 0.0 [1.] [5.378164e-08]\n"
     ]
    }
   ],
   "source": [
    "# %load simple_linear_regression_gd_tf_test.py\n",
    "import tensorflow as tf\n",
    "\n",
    "## 데이터 수집\n",
    "\n",
    "x_data = [1, 2, 3]\n",
    "y_data = [1, 2, 3]\n",
    "\n",
    "## 예측 모델 정의\n",
    "\n",
    "W = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n",
    "b = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n",
    "y = W * x_data + b            #예측값\n",
    "\n",
    "## 비용 함수, 최적화 함수 정의\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(y - y_data))     # reduce_mean 함수로 벡터값을 스칼라값으로 바꿔줌. \n",
    "a = tf.Variable(0.1) # learning rate, alpha      # 학습률을 변경할수도 있기때문에 변수지정\n",
    "optimizer = tf.train.GradientDescentOptimizer(a)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# 변수 초기화\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "## 훈련\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for step in range(2001):\n",
    "    sess.run(train)\n",
    "    if step % 20 == 0:\n",
    "        print(step, sess.run(cost), sess.run(W), sess.run(b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.27868378 [0.83903193] [0.83321875]\n",
      "20 0.031097291 [0.7951872] [0.4655877]\n",
      "40 0.011749391 [0.8741064] [0.2861857]\n",
      "60 0.004439239 [0.92261624] [0.17591162]\n",
      "80 0.0016772639 [0.952434] [0.1081287]\n",
      "100 0.00063371385 [0.9707624] [0.06646419]\n",
      "120 0.00023943534 [0.98202825] [0.04085392]\n",
      "140 9.046402e-05 [0.98895323] [0.02511194]\n",
      "160 3.418072e-05 [0.9932098] [0.01543573]\n",
      "180 1.2914325e-05 [0.99582624] [0.00948798]\n",
      "200 4.8793504e-06 [0.99743444] [0.00583199]\n",
      "220 1.8435109e-06 [0.99842304] [0.00358478]\n",
      "240 6.9656863e-07 [0.99903065] [0.00220348]\n",
      "260 2.6317497e-07 [0.9994042] [0.00135444]\n",
      "280 9.9434146e-08 [0.9996338] [0.00083252]\n",
      "300 3.757665e-08 [0.99977493] [0.00051171]\n",
      "320 1.4185143e-08 [0.9998617] [0.00031446]\n",
      "340 5.3584586e-09 [0.999915] [0.00019329]\n",
      "360 2.028192e-09 [0.9999477] [0.0001188]\n",
      "380 7.652119e-10 [0.9999679] [7.300889e-05]\n",
      "400 2.891293e-10 [0.9999803] [4.491523e-05]\n",
      "420 1.097078e-10 [0.99998784] [2.7606031e-05]\n",
      "440 4.1874653e-11 [0.99999255] [1.6980512e-05]\n",
      "460 1.5101401e-11 [0.99999535] [1.0400159e-05]\n",
      "480 5.968559e-12 [0.99999714] [6.41857e-06]\n",
      "500 2.0842588e-12 [0.9999982] [3.9628585e-06]\n",
      "520 8.9528385e-13 [0.9999989] [2.4290327e-06]\n",
      "540 3.2684966e-13 [0.99999934] [1.515095e-06]\n",
      "560 9.473903e-14 [0.9999996] [9.0315456e-07]\n",
      "580 6.158037e-14 [0.99999964] [6.8857804e-07]\n",
      "600 6.158037e-14 [0.99999976] [5.6142153e-07]\n",
      "620 3.7895614e-14 [0.9999999] [3.071083e-07]\n",
      "640 4.7369517e-15 [0.99999994] [1.3226793e-07]\n",
      "660 0.0 [1.] [5.2795066e-08]\n",
      "680 0.0 [1.] [5.2795066e-08]\n",
      "700 0.0 [1.] [5.2795066e-08]\n",
      "720 0.0 [1.] [5.2795066e-08]\n",
      "740 0.0 [1.] [5.2795066e-08]\n",
      "760 0.0 [1.] [5.2795066e-08]\n",
      "780 0.0 [1.] [5.2795066e-08]\n",
      "800 0.0 [1.] [5.2795066e-08]\n",
      "820 0.0 [1.] [5.2795066e-08]\n",
      "840 0.0 [1.] [5.2795066e-08]\n",
      "860 0.0 [1.] [5.2795066e-08]\n",
      "880 0.0 [1.] [5.2795066e-08]\n",
      "900 0.0 [1.] [5.2795066e-08]\n",
      "920 0.0 [1.] [5.2795066e-08]\n",
      "940 0.0 [1.] [5.2795066e-08]\n",
      "960 0.0 [1.] [5.2795066e-08]\n",
      "980 0.0 [1.] [5.2795066e-08]\n",
      "1000 0.0 [1.] [5.2795066e-08]\n",
      "1020 0.0 [1.] [5.2795066e-08]\n",
      "1040 0.0 [1.] [5.2795066e-08]\n",
      "1060 0.0 [1.] [5.2795066e-08]\n",
      "1080 0.0 [1.] [5.2795066e-08]\n",
      "1100 0.0 [1.] [5.2795066e-08]\n",
      "1120 0.0 [1.] [5.2795066e-08]\n",
      "1140 0.0 [1.] [5.2795066e-08]\n",
      "1160 0.0 [1.] [5.2795066e-08]\n",
      "1180 0.0 [1.] [5.2795066e-08]\n",
      "1200 0.0 [1.] [5.2795066e-08]\n",
      "1220 0.0 [1.] [5.2795066e-08]\n",
      "1240 0.0 [1.] [5.2795066e-08]\n",
      "1260 0.0 [1.] [5.2795066e-08]\n",
      "1280 0.0 [1.] [5.2795066e-08]\n",
      "1300 0.0 [1.] [5.2795066e-08]\n",
      "1320 0.0 [1.] [5.2795066e-08]\n",
      "1340 0.0 [1.] [5.2795066e-08]\n",
      "1360 0.0 [1.] [5.2795066e-08]\n",
      "1380 0.0 [1.] [5.2795066e-08]\n",
      "1400 0.0 [1.] [5.2795066e-08]\n",
      "1420 0.0 [1.] [5.2795066e-08]\n",
      "1440 0.0 [1.] [5.2795066e-08]\n",
      "1460 0.0 [1.] [5.2795066e-08]\n",
      "1480 0.0 [1.] [5.2795066e-08]\n",
      "1500 0.0 [1.] [5.2795066e-08]\n",
      "1520 0.0 [1.] [5.2795066e-08]\n",
      "1540 0.0 [1.] [5.2795066e-08]\n",
      "1560 0.0 [1.] [5.2795066e-08]\n",
      "1580 0.0 [1.] [5.2795066e-08]\n",
      "1600 0.0 [1.] [5.2795066e-08]\n",
      "1620 0.0 [1.] [5.2795066e-08]\n",
      "1640 0.0 [1.] [5.2795066e-08]\n",
      "1660 0.0 [1.] [5.2795066e-08]\n",
      "1680 0.0 [1.] [5.2795066e-08]\n",
      "1700 0.0 [1.] [5.2795066e-08]\n",
      "1720 0.0 [1.] [5.2795066e-08]\n",
      "1740 0.0 [1.] [5.2795066e-08]\n",
      "1760 0.0 [1.] [5.2795066e-08]\n",
      "1780 0.0 [1.] [5.2795066e-08]\n",
      "1800 0.0 [1.] [5.2795066e-08]\n",
      "1820 0.0 [1.] [5.2795066e-08]\n",
      "1840 0.0 [1.] [5.2795066e-08]\n",
      "1860 0.0 [1.] [5.2795066e-08]\n",
      "1880 0.0 [1.] [5.2795066e-08]\n",
      "1900 0.0 [1.] [5.2795066e-08]\n",
      "1920 0.0 [1.] [5.2795066e-08]\n",
      "1940 0.0 [1.] [5.2795066e-08]\n",
      "1960 0.0 [1.] [5.2795066e-08]\n",
      "1980 0.0 [1.] [5.2795066e-08]\n",
      "2000 0.0 [1.] [5.2795066e-08]\n",
      "[2.]\n"
     ]
    }
   ],
   "source": [
    "# %load simple_linear_regression_gd_tf_placeholder_test.py\n",
    "import tensorflow as tf\n",
    "\n",
    "## 데이터 수집\n",
    "\n",
    "x_data = [1, 2, 3]\n",
    "y_data = [1, 2, 3]\n",
    "\n",
    "## 예측 모델 정의\n",
    "\n",
    "X = tf.placeholder(\"float\")\n",
    "y = tf.placeholder(\"float\")\n",
    "W = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n",
    "b = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n",
    "pred = W * X + b\n",
    "\n",
    "## 비용 함수, 최적화 함수 정의\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(pred - y))\n",
    "a = tf.Variable(0.1) # learning rate, alpha\n",
    "optimizer = tf.train.GradientDescentOptimizer(a)\n",
    "train = optimizer.minimize(cost)\n",
    "# 변수 초기화\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "## 훈련\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for step in range(2001):\n",
    "    sess.run(train, feed_dict = {X: x_data, y: y_data}) \n",
    "    if step % 20 == 0:\n",
    "        cost_, W_, b_ = sess.run([cost, W, b], feed_dict = {X: x_data, y: y_data}) \n",
    "        print(step, cost_, W_, b_)\n",
    "\n",
    "print(sess.run(pred, feed_dict = {X: [2]}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age     sex   bmi  children smoker     region  expenses\n",
      "0   19  female  27.9         0    yes  southwest  16884.92\n",
      "1   18    male  33.8         1     no  southeast   1725.55\n",
      "2   28    male  33.0         3     no  southeast   4449.46\n",
      "3   33    male  22.7         0     no  northwest  21984.47\n",
      "4   32    male  28.9         0     no  northwest   3866.86\n"
     ]
    }
   ],
   "source": [
    "# %load insurance_simple_linear_regression_gd_tf_test.py\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "## 데이터 수집\n",
    "\n",
    "insurance = pd.read_csv(\"insurance.csv\")\n",
    "print(insurance[0:5])\n",
    "\n",
    "age = insurance[\"age\"].values\n",
    "expenses = insurance[\"expenses\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 텐서보드 (TensorBoard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "알고리듬이 어떻게 돌아가고 있는지 알려주기 위해 많은 정보를 모니터링하고 디스플레이해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!c:\\anaconda3\\scripts\\tensorboard --logdir /tmp/summary_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load summary_test.py\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "## 데이터 수집\n",
    "\n",
    "x_data = [1, 2, 3]\n",
    "y_data = [1, 2, 3]\n",
    "\n",
    "## 예측 모델 정의\n",
    "\n",
    "W = tf.get_variable(\"W\", initializer=tf.random_uniform([1], -1.0, 1.0))\n",
    "b = tf.get_variable(\"b\", initializer=tf.random_uniform([1], -1.0, 1.0))\n",
    "y = W * x_data + b\n",
    "\n",
    "## 비용 함수, 최적화 함수 정의\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(y - y_data))\n",
    "alpha = tf.get_variable(\"alpha\", initializer=0.01) # learning rate, alpha\n",
    "optimizer = tf.train.GradientDescentOptimizer(alpha)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "## 초기화, summary and graph log\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "tf.summary.scalar(\"cost\", cost)\n",
    "tf.summary.scalar(\"W\", W[0])\n",
    "tf.summary.scalar(\"b\", b[0])\n",
    "\n",
    "summary_op = tf.summary.merge_all()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "sess = tf.Session()\n",
    "summary_writer = tf.summary.FileWriter(\"summary_logs/\", sess.graph)\n",
    "sess.run(init)\n",
    "\n",
    "## 훈련\n",
    "\n",
    "for step in range(500):\n",
    "    sess.run(train)\n",
    "    if step % 20 == 0:\n",
    "        print(step, sess.run(cost), sess.run(W), sess.run(b))\n",
    "    summary_str = sess.run(summary_op)\n",
    "    summary_writer.add_summary(summary_str, step)\n",
    "    saver.save(sess, \"summary_logs/model-checkpoint\", global_stbep=step)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://localhost:6006 방문"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!c:\\Anaconda3\\tensorboard --logdir /tmp/mnist_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load mnist_softmax_gd_tf_summary_test.py\n",
    "# Copyright (c) 2016-2017, Deogtae Kim & DTWARE Inc. All rights reserved.\n",
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \",\"\n",
    "# del os.environ[\"CUDA_VISIBLE_DEVICES\"]\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(107)\n",
    "\n",
    "## 데이터 수집\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "\n",
    "## 데이터 시각화, 전처리\n",
    "\n",
    "print(type(mnist.train))\n",
    "print(dir(mnist))\n",
    "print(type(mnist.train.images), type(mnist.train.labels))\n",
    "print(mnist.train.images.shape)\n",
    "print(mnist.train.images[0].shape)\n",
    "print(mnist.train.images[0])\n",
    "print(mnist.train.labels.shape)\n",
    "print(mnist.train.labels[0].shape)\n",
    "print(mnist.train.labels[0])\n",
    "print(mnist.train.num_examples, mnist.train.images.shape, mnist.train.labels.shape)\n",
    "print(mnist.validation.num_examples, mnist.validation.images.shape, mnist.validation.labels.shape)\n",
    "print(mnist.test.num_examples, mnist.test.images.shape, mnist.test.labels.shape)\n",
    "\n",
    "fig, axes = plt.subplots(5, 5)\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        axes[i,j].axis('off')\n",
    "        axes[i,j].imshow(mnist.train.images[i*5+j].reshape(28,28))\n",
    "        axes[i,j].set_title(\"%d\" % np.argmax(mnist.train.labels[i*5+j]))\n",
    "\n",
    "## 예측 모델 정의: 소프트맥스 회귀 모델\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "W = tf.get_variable(\"W\", initializer=tf.zeros([784, 10]))\n",
    "b = tf.get_variable(\"b\", initializer=tf.zeros([10]))\n",
    "# 각 데이터에 대한 각 분류별 점수\n",
    "score = tf.matmul(X, W) + b\n",
    "# 각 데이터에 대한 각 분류별 확률\n",
    "pred = tf.nn.softmax(score)\n",
    "\n",
    "## 손실 함수, 정확도, 최적화 함수 정의\n",
    "\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(pred), reduction_indices=[1]))\n",
    "correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "#train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cost)\n",
    "train_step = tf.train.AdamOptimizer(0.001).minimize(cost)\n",
    "\n",
    "# 로그 초기화\n",
    "\n",
    "tf.summary.histogram(\"W histogram\", W)\n",
    "tf.summary.histogram(\"b histogram\", b)\n",
    "tf.summary.scalar(\"cost\", cost)\n",
    "tf.summary.scalar(\"accuracy\", accuracy)\n",
    "\n",
    "summary_op = tf.summary.merge_all()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "sess = tf.Session()\n",
    "summary_writer = tf.summary.FileWriter(\"mnist_logs/\", sess.graph)\n",
    "\n",
    "## 훈련\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "import time\n",
    "start = time.time()\n",
    "for epoch in range(50):\n",
    "    avg_cost = 0\n",
    "    batch_count = int(mnist.train.num_examples / 100)\n",
    "    for _ in range(batch_count):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "        c, _  = sess.run([cost, train_step], feed_dict={X: batch_xs, Y: batch_ys})\n",
    "        avg_cost += c / batch_count\n",
    "#    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost), \n",
    "#          ', accuacy = ', '{:.9f}'.format(sess.run(accuracy, feed_dict={X: mnist.test.images, Y: mnist.test.labels})))\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost), \n",
    "          ', validation accuacy = ', '{:.9f}'.format(sess.run(accuracy, feed_dict={X: mnist.validation.images, Y: mnist.validation.labels})))\n",
    "    summary_str = sess.run(summary_op, feed_dict={X: mnist.validation.images, Y: mnist.validation.labels})\n",
    "    summary_writer.add_summary(summary_str, epoch)\n",
    "    saver.save(sess, \"mnist_logs/model-checkpoint\", global_step=epoch)\n",
    "    \n",
    "print('accuacy = ', '{:.9f}'.format(sess.run(accuracy, feed_dict={X: mnist.test.images, Y: mnist.test.labels})))\n",
    "print(\"훈련 시간:\", time.time() - start)  \n",
    "\n",
    "## 모델 평가\n",
    "\n",
    "print(sess.run(accuracy, feed_dict={X: mnist.test.images, Y: mnist.test.labels}))\n",
    "sess.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://localhost:6006 방문"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
